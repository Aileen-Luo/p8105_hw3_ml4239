---
title: "p8105_hw3_ml4239"
Author: "Man Luo"
Date: 2018-10-15
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(tidyr)
library(ggridges)
library(patchwork)
library(ggExtra)
```

#P.1
data cleaning 
```{r}
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("brfss_smart2010") 
brfss<-brfss_smart2010 %>% 
  janitor::clean_names() %>%  #format the data to use appropriate variable names;
  filter(topic == "Overall Health") %>% #focus on the “Overall Health” topic
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% #include only responses from “Excellent” to “Poor”
  mutate(response = forcats::fct_relevel(response, c("Excellent", "Very good", "Good", "Fair", "Poor"))) #organize responses as a factor taking levels ordered from “Excellent” to “Poor”
  str(brfss$response)
```

##1.1
In 2002, which states were observed at 7 locations?
```{r}
brfss%>% 
  filter(year == 2002) %>% 
  group_by(year,locationabbr) %>% 
  summarise(n_location = n_distinct(locationdesc)) %>% 
  filter(n_location == 7)
```

**Comments** In 2002, there are three states which were observed at 7 locations: CT, FL, NC

##1.2
Make a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010.

```{r}
unique(brfss$year)
  brfss%>% 
    group_by(year,locationabbr) %>% 
    summarise(n_location = n_distinct(locationdesc)) %>% 
    ggplot(aes(x = year, y = n_location, color = locationabbr)) +
    geom_point() +
    geom_line() +
    labs(
    title = "Spaghetti plot of number of locations in each state from 2002 to 2010",
    x = "Year",
    y = "Number of locations"
  )
    
```

**Comments**the number of locations(distinct) in FL change the most from 2002 to 2010 expecially in 2007. In other states the distinct number of locations lies between 1 to 20 and do not change a lot.

##1.3
Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.


```{r}
brfss %>% 
  filter(year %in% c(2002,2006,2010) & locationabbr == "NY") %>% 
  filter(response == "Excellent") %>% 
  group_by(year) %>% 
  summarise(mean_excellent = mean(data_value, na.rm = T),
            sd_excellent = sd(data_value, na.rm = T)) %>% 
  knitr::kable(digits = 3)
```

**Comments**The mean proportions of “Excellent” responses across locations in NY State are quite similar between 2006 and 2010. And for 2002 the mean proportion is a little higher than 2006and 2010. The standard deviation of the proportion of “Excellent” responses across locations in NY State is the greatest for 2002, and 2010 has the lowest standart deviation.

##1.4
For each year and state, compute the average proportion in each response category (taking the average across locations in a state). Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time.

```{r}
brfss %>% 
  group_by(year, locationabbr, response) %>% 
  summarise(ave_proportion = mean(data_value)) %>% 
  ggplot(aes(x = year, y = ave_proportion, color = locationabbr))+
  geom_point()+
  geom_line()+
  facet_grid(~response) +
  labs(
    title = "Distribution of State-level Averages Proportion in Each Response for Each Year ",
    x = "Year",
    y = "Average proportion"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5,size = 8), legend.position = "right") 
  
```

**Comments**There are five clusters of data points in the spaghetti plots.The mean proportions of each response type have roughly the same center and range across states across years from 2002 to 2010.The distribution of average proportions of "Poor" responses has the least variation. The distribution of average proportions of "Very good" responses seems to have the greatest variation. 

#P.2



```{r}
 data("instacart")
instacart %>% 
  anyNA()
```
The dimension of the dataset is `r dim(instacart)`.The dataset contains `nrow(instacart)` observations of `crow(instacart)` unique users. And there is no missing value. Each row shows some information about order,product and customer of an ordered product. There are r nrow(distinct(instacart, user_id)) distinct users and r nrow(distinct(instacart, product_id)) distinct products purchased by customers. The data structure of the dataset is `str(instacart)`. There are key descriptition variables: "product_name" (such as "Bulgarian Yogurt","Organic Celery Hearts"),"department" (such as "dairy eggs"，"produce"，"canned goods",etc) and "ordered_number"


##2.1

How many aisles are there, and which aisles are the most items ordered from?
```{r}
instacart %>% 
  summarise(aisles_unique = n_distinct(aisle))

instacart %>% 
  group_by(aisle) %>% 
  summarize(n_by_aisle = n()) %>% 
  arrange(desc(n_by_aisle)) %>% 
  head(3)
```

**Comments** There are 134 aisles recorded in the dataset. and the most items are ordered is from ailse `fresh vegetables`,`fresh fruits` and `packaged vegetables fruits` (The first two nearly the same and packaged vegetables fruites is half of the first two )

##2.2

Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.

```{r, fig.height = 18 }
instacart %>%
  ggplot(aes(x = aisle, fill = department)) + 
  geom_bar()+
  coord_flip()+
  viridis::scale_color_viridis(discrete = TRUE)+
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5,size = 5.5),legend.position = "right")+
  labs(
    title = "scatterplot of number of items ordered from each aisle",
    x = "aisle name",
    y = "number of items"
  )
  
  
```

##2.3
Make a table showing the most popular item in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle,product_name) %>% 
  summarise(n_product = n()) %>% 
  mutate(rank = min_rank(desc(n_product))) %>% 
  filter(rank < 2) %>% 
  knitr::kable()
```

**Comments** Based on the table, we can tell that `Light Brown Sugar` is the most popular product in baking ingredients and it has been ordered 499. For dog food care, `Snack Sticks Chicken & Rice Recipe Dog Treats` is the most popular item in dog food care and and it has been ordered 30. `Organic Baby Spinach` is the most popular item in  `packaged vegetables fruits ` and it has been ordered 9784.

##2.4
Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table)

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name,order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  spread(key = "order_dow", value = "mean_hour")  %>% 
  knitr::kable()
  
```

**Comments** Based on the table, we can tell that every day people tend to order Pink Lady Apples at arbound 11:00 to 14:30 and order Coffee Ice Cream at around 12:30 to 15:30. And the mean hour does not change a lot among different days in the week. 
